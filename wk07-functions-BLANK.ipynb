{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5320cbbf",
   "metadata": {},
   "source": [
    "# Homework for Week 7\n",
    "## Functions and Downloading documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5db5b3",
   "metadata": {},
   "source": [
    "### Write modular functions for the following:\n",
    "\n",
    "1. Making a ```request```\n",
    "2. Converting a ```response``` into ```soup```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b96b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. code here for requests function (create cells if/as needed)\n",
    "\n",
    "import time\n",
    "from random import randrange\n",
    "\n",
    "def sleep(start,end):\n",
    "    \n",
    "    snoozer = randrange(5,12)\n",
    "    print(f\"Snoozing for {snoozer} seconds before next scrape\")\n",
    "    time.sleep(snoozer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed087ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. code here for response function (create cells if/as needed)\n",
    "\n",
    "from bs4 import BeautifulSoup  ## scrape info from web pages\n",
    "import requests ## get web pages from server\n",
    "import time # time is required. we will use its sleep function\n",
    "from random import randrange # generate random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1de36c23-61c6-45ae-a176-bc68a52b03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def requestget(url):\n",
    "    response = requests.get(url)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ac9091e-8bee-41fd-b7c7-1e3d23778cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responsetoSoup(response):\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad90c4f-816b-4341-9b21-653c09f084b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /Users/gennacontino/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c1f364c-0900-4d88-b97e-ece42a25120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c0608a2-2c25-464e-a291-18b5a4c28267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requestget(\"https://sandeepmj.github.io/scrape-example-page/pages.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6072d3b0-7303-4452-be1f-16853ac8f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350b62c",
   "metadata": {},
   "source": [
    "### 3. Demo downloading files from websites \n",
    "\n",
    "There are ```txt``` and ```pdf``` files <a href=\"https://sandeepmj.github.io/scrape-example-page/pages.html\">on this site</a>. During class we downloaded on e set of text files and one set of PDF files.\n",
    "\n",
    "Now download **ALL files at one time**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a209478",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here (create cells if/as needed)\n",
    "\n",
    "url = \"https://sandeepmj.github.io/scrape-example-page/pages.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e10706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/pdf_1.pdf\">1</a>,\n",
       " <a href=\"files/pdf_2.pdf\">2</a>,\n",
       " <a href=\"files/pdf_3.pdf\">3</a>,\n",
       " <a href=\"files/pdf_4.pdf\">4</a>,\n",
       " <a href=\"files/pdf_5.pdf\">5</a>,\n",
       " <a href=\"files/pdf_6.pdf\">6</a>,\n",
       " <a href=\"files/pdf_7.pdf\">7</a>,\n",
       " <a href=\"files/pdf_8.pdf\">8</a>,\n",
       " <a href=\"files/pdf_9.pdf\">9</a>,\n",
       " <a href=\"files/pdf_10.pdf\">10</a>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfs = soup.find(\"ul\", class_ = \"pdfs\").find_all(\"a\")\n",
    "pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f2b7f5-9c06-4e6f-96aa-6bc063e462a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this first set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       " </ul>,\n",
       " <ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this second set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_files = soup.find_all(\"ul\", class_ = \"txts\")\n",
    "txt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034d5666-47e2-4ca3-870b-998805c8dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://sandeepmj.github.io/scrape-example-page/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48435807-bf02-4ed2-8974-88ded6f9fb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_02.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_03.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_04.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_05.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_06.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_07.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_08.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_09.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_10.txt\">10</a>],\n",
       " [<a href=\"files/text_doc_A.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_B.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_C.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_D.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_E.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_F.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_G.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_H.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_I.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_J.txt\">10</a>]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links = []\n",
    "for txt in txt_files:\n",
    "    links = txt.find_all(\"a\")\n",
    "    all_links.append(links)\n",
    "\n",
    "all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1db4b453-8681-4bd4-a1dd-0cf2dc3dd5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/pdf_1.pdf\">1</a>,\n",
       " <a href=\"files/pdf_2.pdf\">2</a>,\n",
       " <a href=\"files/pdf_3.pdf\">3</a>,\n",
       " <a href=\"files/pdf_4.pdf\">4</a>,\n",
       " <a href=\"files/pdf_5.pdf\">5</a>,\n",
       " <a href=\"files/pdf_6.pdf\">6</a>,\n",
       " <a href=\"files/pdf_7.pdf\">7</a>,\n",
       " <a href=\"files/pdf_8.pdf\">8</a>,\n",
       " <a href=\"files/pdf_9.pdf\">9</a>,\n",
       " <a href=\"files/pdf_10.pdf\">10</a>,\n",
       " [<a href=\"files/text_doc_01.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_02.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_03.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_04.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_05.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_06.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_07.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_08.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_09.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_10.txt\">10</a>],\n",
       " [<a href=\"files/text_doc_A.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_B.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_C.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_D.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_E.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_F.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_G.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_H.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_I.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_J.txt\">10</a>]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_link = pdfs + all_links\n",
    "total_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eeef875b-1795-4a26-82f6-4ea3458c48de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " <a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>,\n",
       " <a href=\"files/text_doc_A.txt\">1</a>,\n",
       " <a href=\"files/text_doc_B.txt\">2</a>,\n",
       " <a href=\"files/text_doc_C.txt\">3</a>,\n",
       " <a href=\"files/text_doc_D.txt\">4</a>,\n",
       " <a href=\"files/text_doc_E.txt\">5</a>,\n",
       " <a href=\"files/text_doc_F.txt\">6</a>,\n",
       " <a href=\"files/text_doc_G.txt\">7</a>,\n",
       " <a href=\"files/text_doc_H.txt\">8</a>,\n",
       " <a href=\"files/text_doc_I.txt\">9</a>,\n",
       " <a href=\"files/text_doc_J.txt\">10</a>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_links = list(itertools.chain(*total_link))\n",
    "updated_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58a3f745-53db-4d96-8489-1c489ba37282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/pdf_1.pdf\">1</a>,\n",
       " <a href=\"files/pdf_2.pdf\">2</a>,\n",
       " <a href=\"files/pdf_3.pdf\">3</a>,\n",
       " <a href=\"files/pdf_4.pdf\">4</a>,\n",
       " <a href=\"files/pdf_5.pdf\">5</a>,\n",
       " <a href=\"files/pdf_6.pdf\">6</a>,\n",
       " <a href=\"files/pdf_7.pdf\">7</a>,\n",
       " <a href=\"files/pdf_8.pdf\">8</a>,\n",
       " <a href=\"files/pdf_9.pdf\">9</a>,\n",
       " <a href=\"files/pdf_10.pdf\">10</a>,\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " <a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>,\n",
       " <a href=\"files/text_doc_A.txt\">1</a>,\n",
       " <a href=\"files/text_doc_B.txt\">2</a>,\n",
       " <a href=\"files/text_doc_C.txt\">3</a>,\n",
       " <a href=\"files/text_doc_D.txt\">4</a>,\n",
       " <a href=\"files/text_doc_E.txt\">5</a>,\n",
       " <a href=\"files/text_doc_F.txt\">6</a>,\n",
       " <a href=\"files/text_doc_G.txt\">7</a>,\n",
       " <a href=\"files/text_doc_H.txt\">8</a>,\n",
       " <a href=\"files/text_doc_I.txt\">9</a>,\n",
       " <a href=\"files/text_doc_J.txt\">10</a>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_links = pdfs + updated_links\n",
    "final_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd681e0e-0084-4f38-a57d-12f9989bdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "from bs4 import BeautifulSoup  ## scrape info from web pages\n",
    "import requests\n",
    "import itertools\n",
    "import wget\n",
    "import time\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56be4c7b-9974-421e-8aca-1ee281789387",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://sandeepmj.github.io/scrape-example-page/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m downloaded_links \u001b[38;5;241m=\u001b[39m [base_url \u001b[38;5;241m+\u001b[39m \u001b[43mlink\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m final_links]\n\u001b[1;32m      3\u001b[0m downloaded_links\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/bs4/element.py:984\u001b[0m, in \u001b[0;36mNavigableString.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    986\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "base_url = \"https://sandeepmj.github.io/scrape-example-page/\"\n",
    "downloaded_links = [base_url + link.get(\"href\") for link in final_links]\n",
    "downloaded_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10cf37d-473e-444f-86ff-7cfbd9908219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
